{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc660767",
   "metadata": {},
   "source": [
    "<div id=\"container\" style=\"position:relative;\">\n",
    "<div style=\"float:left\">\n",
    "\n",
    "***Kazi Shahid***\n",
    "\n",
    "***BrainStation Data Science Diploma Candidate***\n",
    "\n",
    "***Capstone Project***\n",
    "\n",
    "=============================================================\n",
    "\n",
    "***Project SteamBuzz: Will Our Game Create a Buzz in the Steam community?***\n",
    "\n",
    "***Part 4: Sentiment Analysis - Supervised Machine Learning Modelling Overview***\n",
    "</div>\n",
    "<div style=\"position:relative; float:right\"><img style=\"height:100px\" src =\"https://i.ibb.co/mcvpL4Z/Steam-Buzz-logo.png\" />\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a41cf",
   "metadata": {},
   "source": [
    "---\n",
    "# Overview\n",
    "\n",
    "In this part, we will discuss the key concepts driving the primary component of the project: the sentiment analysis. The discussion includes a high-level overview of sentiment analysis, supervised machine learning (\"ML\") for sentiment analysis, selection of ML classifiers for the sentiment analysis for this project, performance measures and the ones selected for this project, hyperparameters and their tuning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014270ea",
   "metadata": {},
   "source": [
    "---\n",
    "# Sentiment Analysis\n",
    "\n",
    "Sentiment analysis is [defined](https://towardsdatascience.com/sentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b) as the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information. It is also sometimes referred to as opinion mining or emotion AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e39a0b",
   "metadata": {},
   "source": [
    "---\n",
    "# Supervised Machine Learning for Sentiment Analysis\n",
    "\n",
    "[Machine learning](https://en.wikipedia.org/wiki/Machine_learning) is the study of computer algorithms that can improve automatically through experience and by the use of data. It is also recognized as the use and development of computer systems that are able to learn and adapt without following explicit instructions. It does so by using algorithms and statistical models with a view to analyzing and drawing inferences from patterns in data.\n",
    "\n",
    "A [popular definition](https://mnassar.github.io/deeplearninghandbook/slides/05_ml.pdf) is that, in ML, \"**A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.**\" *(Tom M. Michell, 1997)*\n",
    "\n",
    "In a supervised ML, a mathematical model of a set of data is built that contains both the inputs and the desired outputs. It has a few categories, such as regression, classification, and active learning. Sentiment analysis falls under the **classification** category where the outputs are restricted to a limited set of values, and through training our ML classifier for the input variables on how they are associated with the output values, we essentially try to train our ML classifier to be able to predict the output values of unseen data passed through as input variables. Based on how many unique values these \"limited set of values\" take, it can be a binary classification (i.e., the output values are limited to two unique values) or a multi-class classification (i.e., the values can take more than two unique values)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4004292",
   "metadata": {},
   "source": [
    "---\n",
    "# Selection of Machine Learning Classifiers for Sentiment Analysis\n",
    "\n",
    "The sentiment analysis part of the project is essentially a binary classification problem, where we are trying to predict whether a set of text in a review point to the review having \"positive\" or \"negative\" sentiment.\n",
    "\n",
    "It is widely known that, [\"traditional machine learning methods such as Naïve Bayes, Logistic Regression and Support Vector Machines (SVM) are widely used for large-scale sentiment analysis because they scale well.\"](https://underthehood.meltwater.com/blog/2019/08/22/deep-learning-models-for-sentiment-analysis/)\n",
    "\n",
    "We therefore chose the ML classifiers listed below the sentiment analysis part of this project:\n",
    "- Logistic Regression\n",
    "- Random Forest Classifier\n",
    "- Naive Bayes Classifier\n",
    "- Support Vector Machine\n",
    "\n",
    "Below are overviews of each of the chosen ML classifiers and our rationale for choosing them for this project.\n",
    "\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "### Overview\n",
    "\n",
    "Logistic regression is [defined](https://www.sciencedirect.com/topics/computer-science/logistic-regression) as a process of modelling the probability of a discrete outcome given an input variable. Most commonly, logistic regression classifiers model a binary outcome, i.e., outputs that constitute two unique values such as positive/negative, true/false, yes/no, etc.\n",
    "\n",
    "Logistic regression is a rather fundamental classifier, a widely popular baseline one due to its simple and uncomplicated nature. However, its simplicity also means that it does not always work well in more complex models. To account for this, we will also employ some more complex classification techniques, as described further below.\n",
    "\n",
    "### Rationale Behind Choosing Logistic Regression Classifier for this Project\n",
    "\n",
    "- Logistic regression is a widely used (most used, in fact) classifier to solve binary classification problems.\n",
    "\n",
    "\n",
    "- Logistic regression is the simplest and most uncomplicated classifier of all, making it a prime baseline classifier candidate.\n",
    "\n",
    "\n",
    "- Insights can be readily derived from a logistic regression, thanks to its easily-interpretable coefficients.\n",
    "\n",
    "\n",
    "## Random Forest Classifier\n",
    "\n",
    "### Overview\n",
    "\n",
    "An RF model is [defined](https://dl.acm.org/doi/10.1145/3357384.3357891) as a set of decision trees each of which is trained using random subsets of features. It uses [bagging and feature randomness](https://askinglot.com/is-random-forest-good-for-text-classification) when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree. Given an instance, the prediction by the RF is obtained via majority voting of the predictions of all the trees in the forest.\n",
    "\n",
    "### Rationale Behind Choosing Random Forest Classifier for this Project\n",
    "\n",
    "- RF classifiers are suitable for dealing with the high dimensional noisy data in text classification.\n",
    "\n",
    "\n",
    "- RF classifiers' decision-based algorithm suits text classification problems in the way that they create DTs on randomly-selected data samples, obtains prediction from each DT, and selects the best solution by means of voting, and provides a fairly good indicator of feature importance as well.\n",
    "\n",
    "\n",
    "## Naive Bayes Classifier\n",
    "\n",
    "### Overview\n",
    "\n",
    "Naive Bayes (\"NB\") classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong (hence \"naïve\") independence assumptions between the features.\n",
    "\n",
    "The NB classifier, more specifically the **multinomial NB** classifier, is mostly used in NLP. According to [its documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html): \"***The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.***\"\n",
    "\n",
    "The NB is called \"naïve\" due to the [assumptions it makes](https://towardsdatascience.com/sentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b):\n",
    "\n",
    "- **Independence Assumption:** NB assumes independence throughout the words in the sentence / document, assigning equal weight to the words.\n",
    "\n",
    "- **Relative Frequencies:** In reality, there can be more positive-sentiment-bearing reviews than negative ones. However, when cleaning datasets we tend to rid the dataset of class imbalance (e.g., gravitate towards 50/50 ratio of classes in binary classification problem). We need to be cognizant of the fact that this may not be the case in the real world.\n",
    "\n",
    "\n",
    "### Rationale Behind Choosing a Naive Bayes Classifier for this Project\n",
    "\n",
    "[Some key rationale](https://www.upgrad.com/blog/multinomial-naive-bayes-explained/) behind choosing a Naive Bayes algorithm for a NLP project such as sentiment analysis:\n",
    "\n",
    "- A NB classifier is **highly scalable** and can handle large datasets fairly easily.\n",
    "\n",
    "\n",
    "- Since a NB classifier only has to calculate probability, it is **easy to implement**.\n",
    "\n",
    "\n",
    "- A NB classifier can be used on **both continuous and discrete data**.\n",
    "\n",
    "\n",
    "- A NB classifier is not suitable for regression (cannot be used for numeric value prediction) and is only used for **text data classification**.\n",
    "\n",
    "\n",
    "## Support Vector Machine\n",
    "\n",
    "### Overview\n",
    "\n",
    "A Support Vector Machine, or SVM, is a classifier that finds an optimal hyperplane that maximizes the margin between two classes. Though it can also be applied as a multi-class classifier by running the necessary number of binary \"one-versus-rest\" SVMs, it is still basically a binary classifier run several times in permutation.\n",
    "\n",
    "A SVM strives to find a line that is in the middle of / evenly spaced between the two classes. This is achieved by maximizing the distance between the *decision boundary* and the *closest points*. The perpendicular line from the decision boundary to the closest points in both classes is called **Support Vector**, which a SVM tries to maximize the length of.\n",
    "\n",
    "The particularities of the SVM, including its hyperparameters, are outlined in its [documentation]((https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)).\n",
    "\n",
    "### Rationale Behind Choosing SVM for this Project\n",
    "\n",
    "Some key rationale behind choosing SVM for a NLP project such as sentiment analysis:\n",
    "\n",
    "- SVM does not work great with regression problem, but is very effective in **binary classification**, i.e., working with a binary target variable.\n",
    "\n",
    "\n",
    "- Many algorithms do not work reliably when **number of features are higher (or *much* higher) than data points (i.e., rows)**, but SVM generally does very well in such cases. NLP-type analyses frequently face this kind of scenario where the number of tokens are so high that they sometimes are close to, or greater than, the number of rows in the dataset.\n",
    "\n",
    "\n",
    "- As the support vectors in a SVM only focus on the data points closest to the line, outliers get ignored, so SVM **works well with datasets that have a lot of outliers** too.\n",
    "\n",
    "\n",
    "- SVM does quite well when the algorithm needs to **unravel complex relationships** in the data. NLP-based projects can be prime examples of such cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15411ec",
   "metadata": {},
   "source": [
    "## Selection of Performance Measure\n",
    "\n",
    "After training a ML model, we need to evaluate how well the model learned from the input variables on the basis of how well it is able to predict the output values. We have a number of performance measures at our disposal to do so. Two of the most common, and useful, performance measures are accuracy scores and precision-recall, along with some related measures or derivatives of these.\n",
    "\n",
    "### Accuracy Score\n",
    "\n",
    "Accuracy is [defined](https://mnassar.github.io/deeplearninghandbook/slides/05_ml.pdf) as the proportion of examples for which the model produces the correct output.\n",
    "\n",
    "One downside of the accuracy score is that it does not give reliable information in case of imbalanced classes. However, for our particular dataset where the class imbalance has been addressed to the point of achieving perfect balance, the accuracy scores should quite accurately portray the model's performance.\n",
    "\n",
    "### Precision and Recall\n",
    "\n",
    "Precision and recall are two of the most important performance measures, which are especially useful in case of imbalanced dataset that we come across often in reality where accuracy score is not reliable.\n",
    "\n",
    "**Precision** measures the proportion of positive identifications that were actually correct.\n",
    "\n",
    "**Recall** measures the proportion of actual positives that were identified correctly.\n",
    "\n",
    "In formulaic expression:\n",
    "\n",
    "$$Precision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "$$Recall = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "### F1-score\n",
    "\n",
    "The F1-score is another popular accuracy measure, which balances the precision and recall measures. F1-score is the harmonic mean of the precision and recall scores, calculated as follows:\n",
    "\n",
    "$$F_1 = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall}$$\n",
    "\n",
    "\n",
    "### Area Under the Receiver-Operating-Characteristic Curve (AUC)\n",
    "\n",
    "The Receiver Operating Characteristic (ROC) curve is formed by plotting the [true positive rate (TPR)](https://www.split.io/glossary/false-positive-rate/#:~:text=The%20true%20positive%20rate%20(TPR,as%20TN%2FTN%2BFP.) against the [false positive rate (FPR)](https://www.ibm.com/support/producthub/icpdata/docs/content/SSQNUZ_latest/wsj/model/wos-quality-fpr.html). The area under the ROC curve (AUC) is an associated metric that represents, after plotting the ROC curve, the measure of the area under the curve.\n",
    "\n",
    "AUC=0 represents a classifier that basically generates a vertical line in the plot (hence the area under this curve i.e. vertical line is zero) and is therefore the worst classifier, not able to predict. The AUC=1 is at the opposite end of the spectrum, represented by a horizontal line, the area under which is 1, i.e., the associated classifier is able to predict perfectly. Midway through stands a random-guessing classifier with AUC=0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c90e44a",
   "metadata": {},
   "source": [
    "## Selection of Hyperparameters\n",
    "\n",
    "Different classifiers employ distinctly different algorithms, utilizing different sets of parameters. Based on what values these parameters take, the respective classifier's classification accuracy can vary. These parameters in such cases are referred to as \"hyperparameters\" as they are the characteristics of a model that are not internal, and their values value cannot be estimated from data but rather need to be iterated through and tuned prior to testing.\n",
    "\n",
    "We will discuss the relevant hyperparameters in each of the respective ML modelling parts of this project. As a quick reference, all the hyperparameters of our selected ML models can be found in the respective documentation links below:\n",
    "- [Hyperparameters for Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "\n",
    "- [Hyperparameters for RF](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "\n",
    "\n",
    "- [Hyperparameters for multinomial NB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n",
    "\n",
    "\n",
    "- [Hyperparameters for SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e4e91",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Hyperparameter tuning is the process of iterating through different values for each (or most) chosen parameters in order to determine a set of optimal hyperparameters for a ML model.\n",
    "\n",
    "A widely popular method of hyperparameter tuning is, after selecting the desired parameters and a range of values for the parameters to iterate through, using Grid Search and cross validation as discussed below.\n",
    "\n",
    "\n",
    "### Grid Search\n",
    "\n",
    "A [grid search](https://towardsdatascience.com/grid-search-for-model-tuning-3319b259367e) builds a model for every combination of hyperparameters specified and evaluates each model. It is used to find the optimal hyperparameters of a model which results in the most \"accurate\" predictions.\n",
    "\n",
    "\n",
    "### Cross Validation\n",
    "\n",
    "Cross validation is the method of splitting the train data into multiple \"folds\", where in each iteration a singular fold is held back and the model is trained on the remaining folds and then tested on the held-back fold that is used to replicate a model testing on actual test data. This process is depicted on a high level in the image below, and is explained further below:\n",
    "\n",
    "<img src=\"https://miro.medium.com/proxy/0*KH3dnbGNcmyV_ODL.png\">\n",
    "\n",
    "\n",
    "#### Validation Set\n",
    "\n",
    "Validation set is extremely useful, e.g., for the purpose of tuning the hyperparameters of a classifier. We fit the model using the train set for different hyperparameters, and then have to test the model for them to identify the optimal value of the hyperparameter. We obviously cannot use the train set to do so (as the model has already learned from it), and if we use the test set, then the model implicitly learns from the Test set as well. The validation set then comes in between, for the purpose of testing the hyperparameters to find its optimal value, so that the test set can finally be used at this optimal value. We obtain the validation set by further bifurcating the original train set into a revised train set (a subset of the original) and a validation set.\n",
    "\n",
    "#### K-Fold Cross Validation\n",
    "\n",
    "One issue with having only one validation set is that the model can still implicitly learn from it and overfit to it. In order to address this issue, cross validation is very useful as it splits up the dataset into multiple permutations where in each iteration the Train and validation set takes up different sections of the dataset (excluding the Test set). We can choose how many splits will be performed as such, and hence the term \"K-Fold\" (i.e., K number of equal splits).\n",
    "\n",
    "In the image above, we see that that whole training dataset were divided into 5 sets for each experiment. Therefore, it constitutes a 5-fold (K=5) cross validation where in each experiment the orange block of data represented the validation set for the respective experiment."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "362px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
